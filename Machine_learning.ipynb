{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 医学生のための機械学習入門\n",
        "\n",
        "このノートブックでは、実際の医療データ（Pima Indians Diabetes Dataset）を用いて機械学習の基礎を学びます。\n",
        "データクリーニングから始めて、**Logistic Regression**と**Decision Tree**の2つのアルゴリズムを実践します。\n",
        "\n",
        "## 目次\n",
        "1. 機械学習とは？医療での応用\n",
        "2. データの準備と探索（実データの使用）\n",
        "3. データクリーニングと欠損値処理\n",
        "4. データの前処理\n",
        "5. Logistic Regression（ロジスティック回帰）\n",
        "6. Decision Tree（決定木）\n",
        "7. モデルの評価と比較\n",
        "8. 臨床での解釈と注意点\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. 機械学習とは？医療での応用\n",
        "\n",
        "機械学習は、データからパターンを学習し、新しいデータに対して予測を行う技術です。\n",
        "\n",
        "### 医療分野での応用例\n",
        "- **診断支援**: 画像診断、検査値からの疾患予測\n",
        "- **予後予測**: 治療効果、生存率の予測\n",
        "- **リスク評価**: 疾患発症リスク、再入院リスクの評価\n",
        "- **個別化医療**: 患者に最適な治療法の選択\n",
        "\n",
        "### 今回扱う問題\n",
        "**糖尿病リスク予測**: 患者の検査値や属性から、糖尿病のリスクを予測します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 必要なライブラリのインポート\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 日本語表示の設定\n",
        "plt.rcParams['font.sans-serif'] = ['Hiragino Sans', 'Yu Gothic', 'Meirio', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "print(\"ライブラリのインポートが完了しました\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. データの準備と探索\n",
        "\n",
        "### Pima Indians Diabetes Dataset\n",
        "実際の医療研究で使用されているデータセットを使用します。このデータは米国アリゾナ州フェニックス近郊のピマ・インディアン女性768名の健康データです。\n",
        "\n",
        "### データの内容\n",
        "- **Pregnancies**: 妊娠回数\n",
        "- **Glucose**: 経口ブドウ糖負荷試験の2時間後血糖値 (mg/dL)\n",
        "- **BloodPressure**: 拡張期血圧 (mmHg)\n",
        "- **SkinThickness**: 上腕三頭筋皮下脂肪厚 (mm)\n",
        "- **Insulin**: 2時間後血清インスリン (μU/ml)\n",
        "- **BMI**: Body Mass Index（体格指数）\n",
        "- **DiabetesPedigreeFunction**: 糖尿病家系関数（遺伝的リスクスコア）\n",
        "- **Age**: 年齢\n",
        "- **Outcome**: 糖尿病診断（1:あり, 0:なし）\n",
        "\n",
        "### データの特徴\n",
        "- **実際の医療データ**: 人為的に作成されたものではない\n",
        "- **欠損値の問題**: 生理学的にありえない0が欠損値として記録されている\n",
        "- **データ収集の課題**: 実際の医療現場でのデータ収集の難しさを反映\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pima Indians Diabetes DatasetをGitHubから読み込み\n",
        "url = \"https://raw.githubusercontent.com/npradaschnor/Pima-Indians-Diabetes-Dataset/master/diabetes.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# データの確認\n",
        "print(\"データの形状:\", df.shape)\n",
        "print(\"\\n列名:\")\n",
        "print(df.columns.tolist())\n",
        "print(\"\\n最初の10行:\")\n",
        "df.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# データの基本統計量\n",
        "print(\"基本統計量:\")\n",
        "print(df.describe())\n",
        "\n",
        "# 糖尿病の有無の分布\n",
        "print(\"\\n糖尿病の分布:\")\n",
        "print(df['Outcome'].value_counts())\n",
        "print(f\"\\n糖尿病の割合: {df['Outcome'].mean()*100:.1f}%\")\n",
        "\n",
        "# データ型の確認\n",
        "print(\"\\nデータ型:\")\n",
        "print(df.dtypes)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## データ品質の確認と「きたない」データの発見\n",
        "\n",
        "### 実際の医療データの問題点\n",
        "実際の医療データには様々な問題が含まれています：\n",
        "\n",
        "1. **欠損値の扱い**: 測定されなかった値が0として記録されている\n",
        "2. **測定エラー**: 機器の故障や人為的ミス\n",
        "3. **データ入力ミス**: 転記ミスや単位の間違い\n",
        "4. **異常値**: 生理学的にありえない値\n",
        "\n",
        "### データ収集時の注意点\n",
        "「きれいな」データを集めるために：\n",
        "- **標準化されたプロトコル**: 測定方法の統一\n",
        "- **欠損値の明確な記録**: NAやNullとして記録\n",
        "- **データ検証**: 入力時の範囲チェック\n",
        "- **定期的な監査**: データ品質の確認\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 生理学的にありえない0の値を確認\n",
        "print(\"各列の0の数:\")\n",
        "print((df == 0).sum())\n",
        "\n",
        "# 0が欠損値として扱われるべき列\n",
        "zero_as_missing = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
        "\n",
        "print(\"\\n\\n生理学的にありえない0の割合:\")\n",
        "for col in zero_as_missing:\n",
        "    zero_count = (df[col] == 0).sum()\n",
        "    zero_percent = zero_count / len(df) * 100\n",
        "    print(f\"{col}: {zero_count}件 ({zero_percent:.1f}%)\")\n",
        "\n",
        "# 0を含む行の例を表示\n",
        "print(\"\\n\\n0を含むデータの例:\")\n",
        "df[df[zero_as_missing].eq(0).any(axis=1)].head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# データの可視化（0を含む生データ）\n",
        "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "# 各特徴量の分布を糖尿病の有無で比較\n",
        "features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', \n",
        "            'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
        "\n",
        "for i, feature in enumerate(features):\n",
        "    df[df['Outcome']==0][feature].hist(bins=30, alpha=0.5, label='健常者', ax=axes[i], color='blue')\n",
        "    df[df['Outcome']==1][feature].hist(bins=30, alpha=0.5, label='糖尿病', ax=axes[i], color='red')\n",
        "    axes[i].set_xlabel(feature)\n",
        "    axes[i].set_ylabel('人数')\n",
        "    axes[i].legend()\n",
        "    axes[i].set_title(f'{feature}の分布')\n",
        "    \n",
        "    # 0の値に赤い線を追加（問題のある値を強調）\n",
        "    if feature in zero_as_missing:\n",
        "        axes[i].axvline(x=0, color='red', linestyle='--', alpha=0.7, label='欠損値(0)')\n",
        "\n",
        "# 最後の軸を削除\n",
        "fig.delaxes(axes[8])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"注意: Glucose, BloodPressure, SkinThickness, Insulin, BMIの0は生理学的にありえない値です。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 相関行列の可視化（生データ）\n",
        "plt.figure(figsize=(10, 8))\n",
        "correlation_matrix = df.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
        "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "plt.title('特徴量間の相関係数（欠損値を含む生データ）', fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "# 糖尿病との相関が高い特徴量\n",
        "print(\"糖尿病(Outcome)との相関係数:\")\n",
        "print(correlation_matrix['Outcome'].sort_values(ascending=False))\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. データクリーニングと欠損値処理\n",
        "\n",
        "### なぜデータクリーニングが重要か？\n",
        "1. **モデルの精度向上**: きれいなデータは良い予測につながる\n",
        "2. **誤った結論の回避**: 欠損値や異常値が結果を歪める\n",
        "3. **臨床的妥当性**: 医学的に意味のある結果を得る\n",
        "\n",
        "### 欠損値処理の方法\n",
        "1. **削除法**: 欠損値を含む行または列を削除\n",
        "2. **補完法**: \n",
        "   - 平均値・中央値での補完\n",
        "   - 前後の値での補完\n",
        "   - 機械学習による予測補完\n",
        "3. **そのまま使用**: アルゴリズムが欠損値を扱える場合\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# データのコピーを作成（元データを保持）\n",
        "df_clean = df.copy()\n",
        "\n",
        "# Step 1: 0を欠損値（NaN）に変換\n",
        "for col in zero_as_missing:\n",
        "    df_clean.loc[df_clean[col] == 0, col] = np.nan\n",
        "\n",
        "# 欠損値の状況を確認\n",
        "print(\"欠損値の数:\")\n",
        "print(df_clean.isnull().sum())\n",
        "print(f\"\\n全体の欠損値の割合: {df_clean.isnull().sum().sum() / (len(df_clean) * len(df_clean.columns)) * 100:.1f}%\")\n",
        "\n",
        "# 欠損値の視覚化\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(df_clean.isnull(), cbar=True, yticklabels=False, cmap='viridis')\n",
        "plt.title('欠損値のパターン（黄色が欠損値）')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 異なる欠損値処理方法の比較\n",
        "\n",
        "# 方法1: 欠損値を含む行を削除\n",
        "df_dropna = df_clean.dropna()\n",
        "print(f\"方法1 - 行削除: {len(df_dropna)}行 (元の{len(df_dropna)/len(df)*100:.1f}%)\")\n",
        "\n",
        "# 方法2: 平均値で補完\n",
        "df_mean = df_clean.copy()\n",
        "for col in zero_as_missing:\n",
        "    mean_val = df_clean[col].mean()\n",
        "    df_mean[col].fillna(mean_val, inplace=True)\n",
        "print(f\"方法2 - 平均値補完: {len(df_mean)}行 (データ保持)\")\n",
        "\n",
        "# 方法3: 中央値で補完\n",
        "df_median = df_clean.copy()\n",
        "for col in zero_as_missing:\n",
        "    median_val = df_clean[col].median()\n",
        "    df_median[col].fillna(median_val, inplace=True)\n",
        "print(f\"方法3 - 中央値補完: {len(df_median)}行 (データ保持)\")\n",
        "\n",
        "# 方法4: 条件付き補完（糖尿病の有無で分けて補完）\n",
        "df_conditional = df_clean.copy()\n",
        "for col in zero_as_missing:\n",
        "    # 健常者の中央値\n",
        "    median_healthy = df_clean[df_clean['Outcome'] == 0][col].median()\n",
        "    # 糖尿病患者の中央値\n",
        "    median_diabetic = df_clean[df_clean['Outcome'] == 1][col].median()\n",
        "    \n",
        "    # 条件付きで補完\n",
        "    df_conditional.loc[(df_conditional[col].isnull()) & (df_conditional['Outcome'] == 0), col] = median_healthy\n",
        "    df_conditional.loc[(df_conditional[col].isnull()) & (df_conditional['Outcome'] == 1), col] = median_diabetic\n",
        "\n",
        "print(f\"方法4 - 条件付き補完: {len(df_conditional)}行 (データ保持)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 欠損値処理前後の分布比較（Glucoseを例に）\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "# 元のデータ（0を含む）\n",
        "axes[0,0].hist(df[df['Outcome']==0]['Glucose'], bins=30, alpha=0.5, label='健常者', color='blue')\n",
        "axes[0,0].hist(df[df['Outcome']==1]['Glucose'], bins=30, alpha=0.5, label='糖尿病', color='red')\n",
        "axes[0,0].axvline(x=0, color='red', linestyle='--', alpha=0.7)\n",
        "axes[0,0].set_title('元データ（0を含む）')\n",
        "axes[0,0].set_xlabel('Glucose')\n",
        "axes[0,0].legend()\n",
        "\n",
        "# 行削除後\n",
        "axes[0,1].hist(df_dropna[df_dropna['Outcome']==0]['Glucose'], bins=30, alpha=0.5, label='健常者', color='blue')\n",
        "axes[0,1].hist(df_dropna[df_dropna['Outcome']==1]['Glucose'], bins=30, alpha=0.5, label='糖尿病', color='red')\n",
        "axes[0,1].set_title(f'行削除後（n={len(df_dropna)}）')\n",
        "axes[0,1].set_xlabel('Glucose')\n",
        "axes[0,1].legend()\n",
        "\n",
        "# 中央値補完後\n",
        "axes[1,0].hist(df_median[df_median['Outcome']==0]['Glucose'], bins=30, alpha=0.5, label='健常者', color='blue')\n",
        "axes[1,0].hist(df_median[df_median['Outcome']==1]['Glucose'], bins=30, alpha=0.5, label='糖尿病', color='red')\n",
        "axes[1,0].set_title('中央値補完後')\n",
        "axes[1,0].set_xlabel('Glucose')\n",
        "axes[1,0].legend()\n",
        "\n",
        "# 条件付き補完後\n",
        "axes[1,1].hist(df_conditional[df_conditional['Outcome']==0]['Glucose'], bins=30, alpha=0.5, label='健常者', color='blue')\n",
        "axes[1,1].hist(df_conditional[df_conditional['Outcome']==1]['Glucose'], bins=30, alpha=0.5, label='糖尿病', color='red')\n",
        "axes[1,1].set_title('条件付き補完後')\n",
        "axes[1,1].set_xlabel('Glucose')\n",
        "axes[1,1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"考察: 条件付き補完は、健常者と糖尿病患者の分布の違いを保持しながら欠損値を処理できています。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 条件付き補完データを採用\n",
        "df_processed = df_conditional.copy()\n",
        "\n",
        "print(\"処理後のデータの確認:\")\n",
        "print(f\"データ形状: {df_processed.shape}\")\n",
        "print(f\"欠損値の数: {df_processed.isnull().sum().sum()}\")\n",
        "\n",
        "# 処理後の基本統計量\n",
        "print(\"\\n処理後の基本統計量:\")\n",
        "print(df_processed.describe())\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. データの前処理\n",
        "\n",
        "クリーニング済みのデータを機械学習モデルに適用する準備をします。\n",
        "\n",
        "### 前処理のステップ\n",
        "1. **特徴量とターゲットの分離**: 説明変数（X）と目的変数（y）を分ける\n",
        "2. **訓練データとテストデータの分割**: モデルの評価のため\n",
        "3. **特徴量の標準化**: スケールを統一（特にLogistic Regressionで重要）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 特徴量とターゲットの分離（クリーニング済みデータを使用）\n",
        "X = df_processed.drop('Outcome', axis=1)  # 説明変数\n",
        "y = df_processed['Outcome']  # 目的変数\n",
        "\n",
        "print(\"特徴量の形状:\", X.shape)\n",
        "print(\"特徴量の列:\", X.columns.tolist())\n",
        "\n",
        "# 訓練データとテストデータの分割（8:2の割合）\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\n訓練データ: {X_train.shape[0]}件\")\n",
        "print(f\"テストデータ: {X_test.shape[0]}件\")\n",
        "\n",
        "# クラスの分布を確認（偏りがないか）\n",
        "print(f\"\\n訓練データの糖尿病割合: {y_train.mean()*100:.1f}%\")\n",
        "print(f\"テストデータの糖尿病割合: {y_test.mean()*100:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 特徴量の標準化\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 標準化前後の比較\n",
        "print(\"標準化前の統計量（訓練データの一部）:\")\n",
        "print(X_train.describe().iloc[:2, :3])\n",
        "print(\"\\n標準化後の統計量:\")\n",
        "print(pd.DataFrame(X_train_scaled, columns=X_train.columns).describe().iloc[:2, :3])\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Logistic Regression（ロジスティック回帰）\n",
        "\n",
        "### ロジスティック回帰とは？\n",
        "- **線形分類器**の一種で、確率を予測します\n",
        "- 0から1の間の値を出力（糖尿病である確率）\n",
        "- 解釈しやすく、医療分野でよく使われます\n",
        "\n",
        "### 医学的な意味\n",
        "- 各検査値が糖尿病リスクにどの程度影響するかがわかる\n",
        "- オッズ比として解釈可能\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Logistic Regressionモデルの作成と訓練\n",
        "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "lr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 予測\n",
        "lr_pred = lr_model.predict(X_test_scaled)\n",
        "lr_pred_proba = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# 精度の評価\n",
        "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
        "print(f\"Logistic Regressionの精度: {lr_accuracy:.3f}\")\n",
        "\n",
        "# 混同行列\n",
        "print(\"\\n混同行列:\")\n",
        "cm_lr = confusion_matrix(y_test, lr_pred)\n",
        "print(cm_lr)\n",
        "\n",
        "# 分類レポート\n",
        "print(\"\\n分類レポート:\")\n",
        "print(classification_report(y_test, lr_pred, target_names=['健常者', '糖尿病']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 特徴量の重要度（係数）の可視化\n",
        "coefficients = pd.DataFrame({\n",
        "    '特徴量': X.columns,\n",
        "    '係数': lr_model.coef_[0]\n",
        "})\n",
        "coefficients = coefficients.sort_values('係数', key=abs, ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(coefficients['特徴量'], coefficients['係数'])\n",
        "plt.xlabel('係数')\n",
        "plt.title('Logistic Regressionの係数（特徴量の重要度）')\n",
        "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"係数の解釈:\")\n",
        "print(\"- 正の係数: その特徴量が大きいほど糖尿病リスクが高い\")\n",
        "print(\"- 負の係数: その特徴量が大きいほど糖尿病リスクが低い\")\n",
        "print(f\"\\n最も重要な特徴量: {coefficients.iloc[0]['特徴量']}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Decision Tree（決定木）\n",
        "\n",
        "### 決定木とは？\n",
        "- **ツリー構造**で分類を行うアルゴリズム\n",
        "- 「もし〜なら」という条件を順番に評価\n",
        "- 視覚的に理解しやすく、解釈が容易\n",
        "\n",
        "### 医学的な意味\n",
        "- 診断フローチャートのような考え方\n",
        "- どの検査値がどの閾値で判断されるかが明確\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Decision Treeモデルの作成と訓練\n",
        "# 注：Decision Treeは標準化が不要なので、元のデータを使用\n",
        "dt_model = DecisionTreeClassifier(\n",
        "    max_depth=4,  # 木の深さを制限（過学習を防ぐ）\n",
        "    min_samples_split=20,  # 分割に必要な最小サンプル数\n",
        "    random_state=42\n",
        ")\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# 予測\n",
        "dt_pred = dt_model.predict(X_test)\n",
        "dt_pred_proba = dt_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# 精度の評価\n",
        "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
        "print(f\"Decision Treeの精度: {dt_accuracy:.3f}\")\n",
        "\n",
        "# 混同行列\n",
        "print(\"\\n混同行列:\")\n",
        "cm_dt = confusion_matrix(y_test, dt_pred)\n",
        "print(cm_dt)\n",
        "\n",
        "# 分類レポート\n",
        "print(\"\\n分類レポート:\")\n",
        "print(classification_report(y_test, dt_pred, target_names=['健常者', '糖尿病']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 特徴量の重要度の可視化\n",
        "feature_importance = pd.DataFrame({\n",
        "    '特徴量': X.columns,\n",
        "    '重要度': dt_model.feature_importances_\n",
        "}).sort_values('重要度', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_importance['特徴量'], feature_importance['重要度'])\n",
        "plt.xlabel('重要度')\n",
        "plt.title('Decision Treeの特徴量重要度')\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"特徴量重要度の解釈:\")\n",
        "print(\"- 値が大きいほど、その特徴量が分類に重要\")\n",
        "print(f\"- 最も重要な特徴量: {feature_importance.iloc[0]['特徴量']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 決定木の可視化（簡易版）\n",
        "from sklearn.tree import plot_tree\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "plot_tree(dt_model, \n",
        "          feature_names=X.columns,\n",
        "          class_names=['健常者', '糖尿病'],\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          fontsize=10)\n",
        "plt.title('決定木の構造', fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"決定木の読み方:\")\n",
        "print(\"- 各ノードで特徴量の条件を評価\")\n",
        "print(\"- True（条件を満たす）なら左、False（満たさない）なら右へ\")\n",
        "print(\"- 色が濃いほど糖尿病の確率が高い\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. モデルの評価と比較\n",
        "\n",
        "### 評価指標の説明\n",
        "- **精度（Accuracy）**: 全体の正解率\n",
        "- **感度（Recall）**: 実際の糖尿病患者を正しく検出する割合\n",
        "- **特異度（Specificity）**: 健常者を正しく判定する割合\n",
        "- **ROC曲線**: 感度と特異度のトレードオフを可視化\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 混同行列の比較\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Logistic Regression\n",
        "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
        "            xticklabels=['健常者', '糖尿病'], yticklabels=['健常者', '糖尿病'])\n",
        "axes[0].set_title('Logistic Regression')\n",
        "axes[0].set_ylabel('実際の診断')\n",
        "axes[0].set_xlabel('予測')\n",
        "\n",
        "# Decision Tree\n",
        "sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues', ax=axes[1],\n",
        "            xticklabels=['健常者', '糖尿病'], yticklabels=['健常者', '糖尿病'])\n",
        "axes[1].set_title('Decision Tree')\n",
        "axes[1].set_ylabel('実際の診断')\n",
        "axes[1].set_xlabel('予測')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 性能指標の比較\n",
        "print(\"モデル性能の比較:\")\n",
        "print(f\"Logistic Regression - 精度: {lr_accuracy:.3f}\")\n",
        "print(f\"Decision Tree - 精度: {dt_accuracy:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ROC曲線の比較\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Logistic Regression\n",
        "fpr_lr, tpr_lr, _ = roc_curve(y_test, lr_pred_proba)\n",
        "auc_lr = auc(fpr_lr, tpr_lr)\n",
        "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {auc_lr:.3f})', linewidth=2)\n",
        "\n",
        "# Decision Tree\n",
        "fpr_dt, tpr_dt, _ = roc_curve(y_test, dt_pred_proba)\n",
        "auc_dt = auc(fpr_dt, tpr_dt)\n",
        "plt.plot(fpr_dt, tpr_dt, label=f'Decision Tree (AUC = {auc_dt:.3f})', linewidth=2)\n",
        "\n",
        "# 対角線（ランダム予測）\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='ランダム予測', linewidth=1)\n",
        "\n",
        "plt.xlabel('偽陽性率 (1 - 特異度)', fontsize=12)\n",
        "plt.ylabel('真陽性率 (感度)', fontsize=12)\n",
        "plt.title('ROC曲線の比較', fontsize=16)\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(\"AUC（Area Under Curve）の解釈:\")\n",
        "print(\"- 1.0に近いほど良いモデル\")\n",
        "print(\"- 0.5はランダム予測と同じ\")\n",
        "print(f\"\\nLogistic Regression AUC: {auc_lr:.3f}\")\n",
        "print(f\"Decision Tree AUC: {auc_dt:.3f}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 8. 臨床での解釈と注意点\n",
        "\n",
        "### モデルの比較\n",
        "\n",
        "**Logistic Regression**\n",
        "- ✅ 線形で解釈しやすい\n",
        "- ✅ 各検査値の影響度が明確\n",
        "- ❌ 複雑な非線形関係を捉えにくい\n",
        "\n",
        "**Decision Tree**\n",
        "- ✅ 診断フローチャートとして理解しやすい\n",
        "- ✅ 非線形な関係も捉えられる\n",
        "- ❌ 過学習しやすい\n",
        "\n",
        "### 臨床応用での注意点\n",
        "\n",
        "1. **これらのモデルは診断支援ツール**\n",
        "   - 最終的な診断は医師が行う\n",
        "   - モデルの予測は参考情報の一つ\n",
        "\n",
        "2. **偽陽性・偽陰性のリスク**\n",
        "   - 偽陰性：糖尿病を見逃す → 重大な結果\n",
        "   - 偽陽性：不要な精密検査 → 患者の負担\n",
        "\n",
        "3. **データの偏り**\n",
        "   - 訓練データの質が予測精度に直結\n",
        "   - 人種、地域、年齢層の偏りに注意\n",
        "\n",
        "4. **閾値の調整**\n",
        "   - 感度重視か特異度重視かは臨床状況による\n",
        "   - スクリーニングでは感度を重視することが多い\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## まとめ\n",
        "\n",
        "この1時間で学んだこと：\n",
        "\n",
        "### 1. 実際の医療データの扱い\n",
        "- **データ品質の問題**: 欠損値が0として記録されている\n",
        "- **データクリーニング**: 生理学的にありえない値の処理\n",
        "- **欠損値補完**: 削除、平均値、中央値、条件付き補完\n",
        "\n",
        "### 2. データ収集の重要性\n",
        "- **「きれいな」データ収集**: 標準化されたプロトコルの重要性\n",
        "- **欠損値の明確な記録**: NAやNullとして記録すべき\n",
        "- **データ検証**: 入力時の範囲チェックの必要性\n",
        "\n",
        "### 3. 機械学習の基礎\n",
        "- データの前処理と標準化\n",
        "- 訓練データとテストデータの分割\n",
        "- モデルの評価方法\n",
        "\n",
        "### 4. Logistic Regression\n",
        "- 線形分類モデル\n",
        "- 各特徴量の影響度が係数として明確\n",
        "- 医学研究でよく使われる\n",
        "\n",
        "### 5. Decision Tree\n",
        "- ツリー構造による分類\n",
        "- 視覚的に理解しやすい\n",
        "- 非線形な関係も捉えられる\n",
        "\n",
        "### 6. モデルの評価\n",
        "- 混同行列：偽陽性・偽陰性の把握\n",
        "- ROC曲線：感度と特異度のバランス\n",
        "- AUC：モデル性能の総合評価\n",
        "\n",
        "### 次のステップ\n",
        "1. **より高度なモデル**\n",
        "   - Random Forest（複数の決定木の組み合わせ）\n",
        "   - Neural Networks（深層学習）\n",
        "   - XGBoost（勾配ブースティング）\n",
        "\n",
        "2. **実データでの練習**\n",
        "   - Kaggleの医療データセット\n",
        "   - UCI Machine Learning Repository\n",
        "\n",
        "3. **医療AI の最新動向**\n",
        "   - 画像診断AI（胸部X線、CT、MRI）\n",
        "   - 自然言語処理（電子カルテ解析）\n",
        "   - 予後予測モデル\n",
        "\n",
        "### 重要な心構え\n",
        "- AIは医師の判断を支援するツール\n",
        "- 倫理的配慮と患者のプライバシー保護\n",
        "- 継続的な学習と最新技術のキャッチアップ\n",
        "\n",
        "**医療×AIは今後ますます重要な分野になります。基礎をしっかり理解して、臨床に活かしていきましょう！**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
